{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../material/data/news_dataset.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#allowed_categories = ['POLITICS', 'TRAVEL', 'SPORTS', 'RELIGION', 'SCIENCE', 'TECH', 'ARTS']\n",
    "allowed_categories = {'POLITICS': 0, 'ENTERTAINMENT': 0, 'HEALTHY LIVING': 0, 'TRAVEL': 0, 'BUSINESS': 0, 'SPORTS':0, 'SCIENCE': 0}\n",
    "\n",
    "#max_per_cat = 1000\n",
    "\n",
    "filtered_data = []\n",
    "filter_date = datetime.strptime('2017-08-01', \"%Y-%m-%d\")\n",
    "\n",
    "for dct in data:\n",
    "    if dct['category'] in allowed_categories:\n",
    "        datetime_object = datetime.strptime(dct['date'], '%Y-%m-%d')\n",
    "        if dct['category'] in ['POLITICS', 'ENTERTAINMENT']:\n",
    "            if datetime_object >= filter_date:\n",
    "                filtered_data.append(dct)\n",
    "                allowed_categories[dct['category']]+=1\n",
    "        else:\n",
    "            filtered_data.append(dct)\n",
    "            allowed_categories[dct['category']]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POLITICS': 7049,\n",
       " 'ENTERTAINMENT': 3058,\n",
       " 'HEALTHY LIVING': 6694,\n",
       " 'TRAVEL': 9887,\n",
       " 'BUSINESS': 5937,\n",
       " 'SPORTS': 4884,\n",
       " 'SCIENCE': 2178}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "politics = []\n",
    "entertainment = []\n",
    "health = []\n",
    "travel = []\n",
    "business = []\n",
    "sports = []\n",
    "science = []\n",
    "\n",
    "for dct in filtered_data:\n",
    "    if dct['category'] == \"POLITICS\":\n",
    "        politics.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"POLITICS\")))\n",
    "    if dct['category'] == \"ENTERTAINMENT\":\n",
    "        entertainment.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"ENTERTAINMENT\")))\n",
    "    if dct['category'] == \"HEALTHY LIVING\":\n",
    "        health.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"HEALTH\")))\n",
    "    if dct['category'] == \"TRAVEL\":\n",
    "        travel.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"TRAVEL\")))\n",
    "    if dct['category'] == \"BUSINESS\":\n",
    "        business.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"BUSINESS\")))\n",
    "    if dct['category'] == \"SPORTS\":\n",
    "        sports.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SPORTS\")))\n",
    "    if dct['category'] == \"SCIENCE\":\n",
    "        science.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SCIENCE\")))\n",
    "        \n",
    "max_samples = 2000\n",
    "politics = random.sample(politics, max_samples)\n",
    "entertainment = random.sample(entertainment, max_samples)\n",
    "health = random.sample(health, max_samples)\n",
    "travel = random.sample(travel, max_samples)\n",
    "business = random.sample(business, max_samples)\n",
    "sports = random.sample(sports, max_samples)\n",
    "science = random.sample(science, max_samples)\n",
    "\n",
    "articles = politics + entertainment + health + travel + business + sports + science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples_per_cat(samples, cats):\n",
    "    counts = {}\n",
    "    for name in cats:\n",
    "        counts[name] = 0\n",
    "    \n",
    "    for corpus, label in samples:\n",
    "        counts[label]+=1\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 2000, 'ENTERTAINMENT': 2000, 'HEALTH': 2000, 'TRAVEL': 2000, 'BUSINESS': 2000, 'SPORTS': 2000, 'SCIENCE': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(articles, ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
    "    final = [stemmer.stem(word) for word in clean]\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_articles = []\n",
    "for corpus, label in articles:\n",
    "    p_corpus = preprocess_document(corpus)\n",
    "    p_articles.append(tuple((p_corpus, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 8603)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "X = [corpus for corpus, label in articles]\n",
    "y = [label for corpus, label in articles]\n",
    "\n",
    "X = tfidf.fit_transform(X).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 1619, 'ENTERTAINMENT': 1628, 'HEALTH': 1606, 'TRAVEL': 1580, 'BUSINESS': 1591, 'SPORTS': 1578, 'SCIENCE': 1598}\n",
      "{'POLITICS': 381, 'ENTERTAINMENT': 372, 'HEALTH': 394, 'TRAVEL': 420, 'BUSINESS': 409, 'SPORTS': 422, 'SCIENCE': 402}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(zip(X_train, y_train), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))\n",
    "print(count_samples_per_cat(zip(X_test, y_test), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_classifier = LogisticRegression(solver='lbfgs', multi_class = 'auto')\n",
    "log_classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[292   7  56  26   7   8  13]\n",
      " [  7 313   8  27   6   6   5]\n",
      " [ 29  14 293  16  21   9  12]\n",
      " [ 17   9  12 327   1   7   8]\n",
      " [ 15  12  57   1 304   7   6]\n",
      " [ 11  23  14   8   6 354   6]\n",
      " [ 17  10  17   3  20   7 346]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.75      0.71      0.73       409\n",
      "ENTERTAINMENT       0.81      0.84      0.82       372\n",
      "       HEALTH       0.64      0.74      0.69       394\n",
      "     POLITICS       0.80      0.86      0.83       381\n",
      "      SCIENCE       0.83      0.76      0.79       402\n",
      "       SPORTS       0.89      0.84      0.86       422\n",
      "       TRAVEL       0.87      0.82      0.85       420\n",
      "\n",
      "    micro avg       0.80      0.80      0.80      2800\n",
      "    macro avg       0.80      0.80      0.80      2800\n",
      " weighted avg       0.80      0.80      0.80      2800\n",
      "\n",
      "0.7960714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 6-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(log_classifier, X, y, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80410607 0.8075278  0.7953668  0.8013728  0.7992278  0.79493779]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "bnb_classifier = BernoulliNB()\n",
    "bnb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bnb_classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  14  73  22   6  14  14]\n",
      " [  1 326   8  19   7   8   3]\n",
      " [ 18  14 315  16  17   5   9]\n",
      " [ 19  11  13 323   0   9   6]\n",
      " [ 10   9  65   1 300   8   9]\n",
      " [  7  28  15   9   5 354   4]\n",
      " [ 15   9  25   3  19   8 341]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.79      0.65      0.71       409\n",
      "ENTERTAINMENT       0.79      0.88      0.83       372\n",
      "       HEALTH       0.61      0.80      0.69       394\n",
      "     POLITICS       0.82      0.85      0.83       381\n",
      "      SCIENCE       0.85      0.75      0.79       402\n",
      "       SPORTS       0.87      0.84      0.86       422\n",
      "       TRAVEL       0.88      0.81      0.85       420\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      2800\n",
      "    macro avg       0.80      0.80      0.80      2800\n",
      " weighted avg       0.80      0.79      0.80      2800\n",
      "\n",
      "0.7946428571428571\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(bnb_classifier, X, y, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79897348, 0.80239521, 0.78549979, 0.7953668 , 0.79279279,\n",
       "       0.7953668 ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_classifier = svm.SVC(gamma='scale', max_iter = 10)\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randforest_classifier = RandomForestClassifier(n_estimators=10, random_state=0)  \n",
    "randforest_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randforest_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(log_classifier, open(\"log_classifier.model\", 'wb'))\n",
    "pickle.dump(tfidf, open(\"tfidf_kaggledataset.model\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3 as urllib\n",
    "urllib.disable_warnings()\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used:  POLITICS ENTERTAINMENT HEALTH TRAVEL BUSINESS SPORTS SCIENCE\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes used: \",'POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyt_retrieve(nyt_rss_url, label): # retrieve articles from New York Times\n",
    "    articles = []\n",
    "    \n",
    "    # code dependent on the nytimes structure of RSS feed\n",
    "    http = urllib.PoolManager()\n",
    "    r = http.request('GET', nyt_rss_url)\n",
    "\n",
    "    data = xmltodict.parse(r.data)\n",
    "    data = data[\"rss\"]\n",
    "    data = data[\"channel\"]\n",
    "    data = data[\"item\"]\n",
    "\n",
    "    for key in data:\n",
    "        article = key\n",
    "        title, descr, extra_descr = \"\", \"\", \"\"\n",
    "        if \"title\" in article and article[\"title\"] is not None:\n",
    "            title = article[\"title\"] + \". \"\n",
    "        if \"media:description\" in article and article[\"media:description\"] is not None:\n",
    "            descr = article[\"media:description\"]\n",
    "        if \"description\" in article and article[\"description\"] is not None:\n",
    "            extra_descr = article[\"description\"]\n",
    "\n",
    "        corpus = str(title) + str(descr) + str(extra_descr)\n",
    "        articles.append(tuple((corpus, label)))\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = []\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Politics.xml', 'POLITICS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Movies.xml', 'ENTERTAINMENT')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Health.xml', 'HEALTH')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Travel.xml', 'TRAVEL')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Business.xml', 'BUSINESS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Sports.xml', 'SPORTS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Science.xml', 'SCIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nyt = []\n",
    "for corpus, label in nyt:\n",
    "    p_nyt.append(tuple((preprocess_document(corpus),label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen, y_unseen = [], []\n",
    "for corpus, label in p_nyt:\n",
    "    X_unseen.append(corpus)\n",
    "    y_unseen.append(label)\n",
    "\n",
    "X_unseen = tfidf.transform(X_unseen).toarray()\n",
    "\n",
    "y_pred = bnb_classifier.predict(X_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  2  1  5  2  1  3]\n",
      " [ 1 27  2  0  2  0  1]\n",
      " [ 4  1 13  7  5  2  1]\n",
      " [ 1  0  0 18  0  0  1]\n",
      " [ 4  0  5  7  8  0  2]\n",
      " [ 1  0  0  0  0 18  1]\n",
      " [ 2  0  0  1  2  0 18]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.72      0.71      0.72        48\n",
      "ENTERTAINMENT       0.90      0.82      0.86        33\n",
      "       HEALTH       0.62      0.39      0.48        33\n",
      "     POLITICS       0.47      0.90      0.62        20\n",
      "      SCIENCE       0.42      0.31      0.36        26\n",
      "       SPORTS       0.86      0.90      0.88        20\n",
      "       TRAVEL       0.67      0.78      0.72        23\n",
      "\n",
      "    micro avg       0.67      0.67      0.67       203\n",
      "    macro avg       0.67      0.69      0.66       203\n",
      " weighted avg       0.68      0.67      0.66       203\n",
      "\n",
      "0.6699507389162561\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_unseen,y_pred))  \n",
    "print(classification_report(y_unseen,y_pred))  \n",
    "print(accuracy_score(y_unseen, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
