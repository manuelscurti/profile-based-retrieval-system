{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim import corpora, models, similarities\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "import urllib3 as urllib\n",
    "urllib.disable_warnings()\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../material/data/news_dataset.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#allowed_categories = ['POLITICS', 'TRAVEL', 'SPORTS', 'RELIGION', 'SCIENCE', 'TECH', 'ARTS']\n",
    "allowed_categories = {'POLITICS': 0, 'ENTERTAINMENT': 0, 'HEALTHY LIVING': 0, 'TRAVEL': 0, 'BUSINESS': 0, 'SPORTS':0, 'SCIENCE': 0}\n",
    "\n",
    "#max_per_cat = 1000\n",
    "\n",
    "filtered_data = []\n",
    "filter_date = datetime.strptime('2017-08-01', \"%Y-%m-%d\")\n",
    "\n",
    "for dct in data:\n",
    "    if dct['category'] in allowed_categories:\n",
    "        datetime_object = datetime.strptime(dct['date'], '%Y-%m-%d')\n",
    "        if dct['category'] in ['POLITICS', 'ENTERTAINMENT']:\n",
    "            if datetime_object >= filter_date:\n",
    "                filtered_data.append(dct)\n",
    "                allowed_categories[dct['category']]+=1\n",
    "        else:\n",
    "            filtered_data.append(dct)\n",
    "            allowed_categories[dct['category']]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POLITICS': 7049,\n",
       " 'ENTERTAINMENT': 3058,\n",
       " 'HEALTHY LIVING': 6694,\n",
       " 'TRAVEL': 9887,\n",
       " 'BUSINESS': 5937,\n",
       " 'SPORTS': 4884,\n",
       " 'SCIENCE': 2178}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "politics = []\n",
    "entertainment = []\n",
    "health = []\n",
    "travel = []\n",
    "business = []\n",
    "sports = []\n",
    "science = []\n",
    "\n",
    "for dct in filtered_data:\n",
    "    if dct['category'] == \"POLITICS\":\n",
    "        politics.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"POLITICS\")))\n",
    "    if dct['category'] == \"ENTERTAINMENT\":\n",
    "        entertainment.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"ENTERTAINMENT\")))\n",
    "    if dct['category'] == \"HEALTHY LIVING\":\n",
    "        health.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"HEALTH\")))\n",
    "    if dct['category'] == \"TRAVEL\":\n",
    "        travel.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"TRAVEL\")))\n",
    "    if dct['category'] == \"BUSINESS\":\n",
    "        business.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"BUSINESS\")))\n",
    "    if dct['category'] == \"SPORTS\":\n",
    "        sports.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SPORTS\")))\n",
    "    if dct['category'] == \"SCIENCE\":\n",
    "        science.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SCIENCE\")))\n",
    "        \n",
    "max_samples = 2000\n",
    "politics = random.sample(politics, max_samples)\n",
    "entertainment = random.sample(entertainment, max_samples)\n",
    "health = random.sample(health, max_samples)\n",
    "travel = random.sample(travel, max_samples)\n",
    "business = random.sample(business, max_samples)\n",
    "sports = random.sample(sports, max_samples)\n",
    "science = random.sample(science, max_samples)\n",
    "\n",
    "articles = politics + entertainment + health + travel + business + sports + science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples_per_cat(samples, cats):\n",
    "    counts = {}\n",
    "    for name in cats:\n",
    "        counts[name] = 0\n",
    "    \n",
    "    for corpus, label in samples:\n",
    "        counts[label]+=1\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 2000, 'ENTERTAINMENT': 2000, 'HEALTH': 2000, 'TRAVEL': 2000, 'BUSINESS': 2000, 'SPORTS': 2000, 'SCIENCE': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(articles, ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_samples(samples, division): # consistent split\n",
    "    \n",
    "    samples_p = [(corpus, label) for (corpus, label) in samples if label == 'POLITICS']\n",
    "    samples_b = [(corpus, label) for (corpus, label) in samples if label == 'ENTERTAINMENT']\n",
    "    samples_t = [(corpus, label) for (corpus, label) in samples if label == 'HEALTH']\n",
    "    samples_s = [(corpus, label) for (corpus, label) in samples if label == 'TRAVEL']\n",
    "    samples_h = [(corpus, label) for (corpus, label) in samples if label == 'BUSINESS']\n",
    "    samples_sp = [(corpus, label) for (corpus, label) in samples if label == 'SPORTS']\n",
    "    samples_a = [(corpus, label) for (corpus, label) in samples if label == 'SCIENCE']\n",
    "    \n",
    "    train_p = samples_p[:int(division*len(samples_p))]\n",
    "    test_p = samples_p[int(division*len(samples_p)):]\n",
    "    \n",
    "    train_b = samples_b[:int(division*len(samples_b))]\n",
    "    test_b = samples_b[int(division*len(samples_b)):]\n",
    "    \n",
    "    train_t = samples_t[:int(division*len(samples_t))]\n",
    "    test_t = samples_t[int(division*len(samples_t)):]\n",
    "    \n",
    "    train_s = samples_s[:int(division*len(samples_s))]\n",
    "    test_s = samples_s[int(division*len(samples_s)):]\n",
    "    \n",
    "    train_h = samples_h[:int(division*len(samples_h))]\n",
    "    test_h = samples_h[int(division*len(samples_h)):]\n",
    "    \n",
    "    train_sp = samples_sp[:int(division*len(samples_sp))]\n",
    "    test_sp = samples_sp[int(division*len(samples_sp)):]\n",
    "\n",
    "    train_a = samples_a[:int(division*len(samples_a))]\n",
    "    test_a = samples_a[int(division*len(samples_a)):]\n",
    "    \n",
    "    trainset = train_p + train_b + train_t + train_s + train_h + train_sp + train_a\n",
    "    testset = test_p + test_b + test_t + test_s + test_h + test_sp + test_a\n",
    "    \n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
    "    final = [stemmer.stem(word) for word in clean]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['legisl', 'would', 'requir', 'transpar', 'facebook', 'googl', 'polit', 'ad', 'sen', 'mark', 'warner', 'ami', 'klobuchar', 'plan', 'introduc', 'new', 'bill', 'soon', 'week', 'came', 'light', 'russian', 'interest', 'bought', 'facebook', 'ad', '2016', 'elect'], 'POLITICS'), (['american', 'defi', 'donald', 'trump', 'pro', 'daca', 'demonstr', 'erupt', 'across', 'countri', 'lo', 'angel', 'new', 'york', 'thousand', 'took', 'street', 'tuesday', 'defenddaca'], 'POLITICS')]\n",
      "13999\n"
     ]
    }
   ],
   "source": [
    "p_articles = []\n",
    "for corpus, title in articles:\n",
    "    p_corpus = preprocess_document(corpus)\n",
    "    if len(p_corpus) > 0:\n",
    "        p_articles.append(tuple((p_corpus, title)))\n",
    "\n",
    "print(p_articles[1:3])\n",
    "print(len(p_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 2000, 'ENTERTAINMENT': 2000, 'HEALTH': 2000, 'TRAVEL': 2000, 'BUSINESS': 2000, 'SPORTS': 2000, 'SCIENCE': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(articles, ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232833\n",
      "<FreqDist with 18390 samples and 232833 outcomes>\n",
      "2000\n",
      "['trump', 'year', 'one', 'time']\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "dict_from_articles = [] # list of all tokens contained in the whole set of articles\n",
    "for tokens, label in p_articles:\n",
    "    dict_from_articles = dict_from_articles + tokens\n",
    "\n",
    "print(len(dict_from_articles))\n",
    "fdist = FreqDist(dict_from_articles) # compute frequency distribution\n",
    "\n",
    "print(fdist)\n",
    "topK = fdist.most_common(2000)\n",
    "\n",
    "dictionary = []\n",
    "for word, count in topK:\n",
    "    dictionary.append(word)\n",
    "    \n",
    "print(len(dictionary))\n",
    "print(dictionary[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MVB_features(tokens):\n",
    "    feature_vec = {}\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if word in tokens:\n",
    "            feature_vec[word] = 1\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "            \n",
    "    return feature_vec\n",
    "\n",
    "def extract_M_features(tokens):\n",
    "    feature_vec = {}\n",
    "    freqs = FreqDist(tokens)\n",
    "        \n",
    "    for word in dictionary:\n",
    "        if word in freqs: # if word appears in the phrase\n",
    "            feature_vec[word] = freqs[word]\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "            \n",
    "    return feature_vec\n",
    "\n",
    "def extract_MNorm_features(tokens):\n",
    "    feature_vec = {}\n",
    "    freqs = FreqDist(tokens)\n",
    "    div = len(tokens)\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if word in freqs: # if word appears in the phrase\n",
    "            feature_vec[word] = freqs[word]\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "        feature_vec[word] = round(feature_vec[word]/div,2)\n",
    "            \n",
    "    return feature_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(p_articles)\n",
    "\n",
    "featuresets_mvb = [(extract_MVB_features(corpus), label) for (corpus, label) in p_articles]\n",
    "featuresets_m = [(extract_M_features(corpus), label) for (corpus, label) in p_articles]\n",
    "featuresets_mn = [(extract_MNorm_features(corpus), label) for (corpus, label) in p_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_mvb, testset_mvb = split_samples(featuresets_mvb, 0.8)\n",
    "trainset_m, testset_m = split_samples(featuresets_m, 0.8)\n",
    "trainset_mn, testset_mn = split_samples(featuresets_mn, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "### Multi-Variate Bernoulli Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVB: 0.7514285714285714\n",
      "Most Informative Features\n",
      "                   trump = 1              POLITI : TRAVEL =    468.3 : 1.0\n",
      "                  travel = 1              TRAVEL : ENTERT =    219.0 : 1.0\n",
      "               scientist = 1              SCIENC : TRAVEL =    139.0 : 1.0\n",
      "                   space = 1              SCIENC : SPORTS =    112.3 : 1.0\n",
      "                     nfl = 1              SPORTS : ENTERT =     98.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "bayes_classifier_mvb = nltk.NaiveBayesClassifier.train(trainset_mvb)\n",
    "print(\"MVB: \"+str(nltk.classify.accuracy(bayes_classifier_mvb, testset_mvb)))\n",
    "bayes_classifier_mvb.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 0.7392857142857143\n",
      "Most Informative Features\n",
      "                   trump = 1              POLITI : TRAVEL =    369.0 : 1.0\n",
      "                  travel = 1              TRAVEL : ENTERT =    143.7 : 1.0\n",
      "               scientist = 1              SCIENC : TRAVEL =    134.3 : 1.0\n",
      "                  presid = 1              POLITI : HEALTH =    115.0 : 1.0\n",
      "                   trump = 2              POLITI : SCIENC =     93.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "bayes_classifier_m = nltk.NaiveBayesClassifier.train(trainset_m)\n",
    "print(\"M: \"+str(nltk.classify.accuracy(bayes_classifier_m, testset_m)))\n",
    "bayes_classifier_m.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNorm: 0.5728571428571428\n",
      "Most Informative Features\n",
      "                   trump = 0.06           POLITI : TRAVEL =    107.0 : 1.0\n",
      "                   trump = 0.05           POLITI : HEALTH =     87.0 : 1.0\n",
      "                   photo = 0.05           TRAVEL : POLITI =     59.7 : 1.0\n",
      "                   trump = 0.08           POLITI : SCIENC =     46.3 : 1.0\n",
      "                  travel = 0.05           TRAVEL : ENTERT =     41.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "bayes_classifier_mn = nltk.NaiveBayesClassifier.train(trainset_mn)\n",
    "print(\"MNorm: \"+str(nltk.classify.accuracy(bayes_classifier_mn, testset_mn)))\n",
    "bayes_classifier_mn.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entropy Classifier\n",
    "\n",
    "### Multi-Variate Bernoulli Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1392: RuntimeWarning: overflow encountered in power\n",
      "  exp_nf_delta = 2 ** nf_delta\n",
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1394: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n",
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1395: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n",
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\nltk\\classify\\maxent.py:1402: RuntimeWarning: invalid value encountered in true_divide\n",
      "  deltas -= (ffreq_empirical - sum1) / -sum2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVB: 0.14285714285714285\n",
      "     nan new==0 and label is 'POLITICS'\n",
      "     nan trump==0 and label is 'POLITICS'\n",
      "     nan year==1 and label is 'POLITICS'\n",
      "     nan one==0 and label is 'POLITICS'\n",
      "     nan time==0 and label is 'POLITICS'\n"
     ]
    }
   ],
   "source": [
    "maxent_classifier_mvb = nltk.classify.MaxentClassifier.train(trainset_mvb, 'IIS', trace=0, max_iter=5)\n",
    "print(\"MVB: \"+str(nltk.classify.accuracy(maxent_classifier_mvb, testset_mvb)))\n",
    "maxent_classifier_mvb.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 0.14285714285714285\n",
      "     nan new==0 and label is 'POLITICS'\n",
      "     nan trump==0 and label is 'POLITICS'\n",
      "     nan year==1 and label is 'POLITICS'\n",
      "     nan one==0 and label is 'POLITICS'\n",
      "     nan time==0 and label is 'POLITICS'\n"
     ]
    }
   ],
   "source": [
    "maxent_classifier_m = nltk.classify.MaxentClassifier.train(trainset_m, 'IIS', trace=0, max_iter=5)\n",
    "print(\"M: \"+str(nltk.classify.accuracy(maxent_classifier_m, testset_m)))\n",
    "maxent_classifier_m.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNorm: 0.14285714285714285\n",
      "     nan new==0.0 and label is 'POLITICS'\n",
      "     nan trump==0.0 and label is 'POLITICS'\n",
      "     nan year==0.05 and label is 'POLITICS'\n",
      "     nan one==0.0 and label is 'POLITICS'\n",
      "     nan time==0.0 and label is 'POLITICS'\n"
     ]
    }
   ],
   "source": [
    "maxent_classifier_mn = nltk.classify.MaxentClassifier.train(trainset_mn, 'IIS', trace=0, max_iter=5)\n",
    "print(\"MNorm: \"+str(nltk.classify.accuracy(maxent_classifier_mn, testset_mn)))\n",
    "maxent_classifier_mn.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
