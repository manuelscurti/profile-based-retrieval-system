{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../material/data/news_dataset.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#allowed_categories = ['POLITICS', 'TRAVEL', 'SPORTS', 'RELIGION', 'SCIENCE', 'TECH', 'ARTS']\n",
    "allowed_categories = {'POLITICS': 0, 'ENTERTAINMENT': 0, 'HEALTHY LIVING': 0, 'TRAVEL': 0, 'BUSINESS': 0, 'SPORTS':0, 'SCIENCE': 0}\n",
    "\n",
    "#max_per_cat = 1000\n",
    "\n",
    "filtered_data = []\n",
    "filter_date = datetime.strptime('2017-08-01', \"%Y-%m-%d\")\n",
    "\n",
    "for dct in data:\n",
    "    if dct['category'] in allowed_categories:\n",
    "        datetime_object = datetime.strptime(dct['date'], '%Y-%m-%d')\n",
    "        if dct['category'] in ['POLITICS', 'ENTERTAINMENT']:\n",
    "            if datetime_object >= filter_date:\n",
    "                filtered_data.append(dct)\n",
    "                allowed_categories[dct['category']]+=1\n",
    "        else:\n",
    "            filtered_data.append(dct)\n",
    "            allowed_categories[dct['category']]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POLITICS': 7049,\n",
       " 'ENTERTAINMENT': 3058,\n",
       " 'HEALTHY LIVING': 6694,\n",
       " 'TRAVEL': 9887,\n",
       " 'BUSINESS': 5937,\n",
       " 'SPORTS': 4884,\n",
       " 'SCIENCE': 2178}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "politics = []\n",
    "entertainment = []\n",
    "health = []\n",
    "travel = []\n",
    "business = []\n",
    "sports = []\n",
    "science = []\n",
    "\n",
    "for dct in filtered_data:\n",
    "    if dct['category'] == \"POLITICS\":\n",
    "        politics.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"POLITICS\")))\n",
    "    if dct['category'] == \"ENTERTAINMENT\":\n",
    "        entertainment.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"ENTERTAINMENT\")))\n",
    "    if dct['category'] == \"HEALTHY LIVING\":\n",
    "        health.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"HEALTH\")))\n",
    "    if dct['category'] == \"TRAVEL\":\n",
    "        travel.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"TRAVEL\")))\n",
    "    if dct['category'] == \"BUSINESS\":\n",
    "        business.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"BUSINESS\")))\n",
    "    if dct['category'] == \"SPORTS\":\n",
    "        sports.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SPORTS\")))\n",
    "    if dct['category'] == \"SCIENCE\":\n",
    "        science.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SCIENCE\")))\n",
    "        \n",
    "max_samples = 2000\n",
    "politics = random.sample(politics, max_samples)\n",
    "entertainment = random.sample(entertainment, max_samples)\n",
    "health = random.sample(health, max_samples)\n",
    "travel = random.sample(travel, max_samples)\n",
    "business = random.sample(business, max_samples)\n",
    "sports = random.sample(sports, max_samples)\n",
    "science = random.sample(science, max_samples)\n",
    "\n",
    "articles = politics + entertainment + health + travel + business + sports + science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples_per_cat(samples, cats):\n",
    "    counts = {}\n",
    "    for name in cats:\n",
    "        counts[name] = 0\n",
    "    \n",
    "    for corpus, label in samples:\n",
    "        counts[label]+=1\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 2000, 'ENTERTAINMENT': 2000, 'HEALTH': 2000, 'TRAVEL': 2000, 'BUSINESS': 2000, 'SPORTS': 2000, 'SCIENCE': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(articles, ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
    "    final = [stemmer.stem(word) for word in clean]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples_per_cat(samples, cats):\n",
    "    counts = {}\n",
    "    for name in cats:\n",
    "        counts[name] = 0\n",
    "    \n",
    "    for corpus, label in samples:\n",
    "        counts[label]+=1\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for corpus, label in articles:\n",
    "    p_corpus = preprocess_document(corpus)\n",
    "    if len(p_corpus) > 0:\n",
    "        X.append(p_corpus)\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 2000, 'ENTERTAINMENT': 2000, 'HEALTH': 1999, 'TRAVEL': 2000, 'BUSINESS': 2000, 'SPORTS': 2000, 'SCIENCE': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(zip(X,y), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233351\n",
      "<FreqDist with 18365 samples and 233351 outcomes>\n",
      "3000\n",
      "['trump', 'one', 'year', 'time']\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "dict_from_articles = [] # list of all tokens contained in the whole train set of articles\n",
    "for tokens in X: \n",
    "    dict_from_articles = dict_from_articles + tokens\n",
    "\n",
    "print(len(dict_from_articles))\n",
    "fdist = FreqDist(dict_from_articles) # compute frequency distribution\n",
    "\n",
    "print(fdist)\n",
    "topK = fdist.most_common(3000)\n",
    "\n",
    "dictionary = []\n",
    "for word, count in topK:\n",
    "    dictionary.append(word)\n",
    "    \n",
    "print(len(dictionary))\n",
    "print(dictionary[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MVB_features(tokens):\n",
    "    feature_vec = {}\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if word in tokens:\n",
    "            feature_vec[word] = 1\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "            \n",
    "    return feature_vec\n",
    "\n",
    "def extract_M_features(tokens):\n",
    "    feature_vec = {}\n",
    "    freqs = FreqDist(tokens)\n",
    "        \n",
    "    for word in dictionary:\n",
    "        if word in freqs: # if word appears in the phrase\n",
    "            feature_vec[word] = freqs[word]\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "            \n",
    "    return feature_vec\n",
    "\n",
    "def extract_MNorm_features(tokens):\n",
    "    feature_vec = {}\n",
    "    freqs = FreqDist(tokens)\n",
    "    div = len(tokens)\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if word in freqs: # if word appears in the phrase\n",
    "            feature_vec[word] = freqs[word]\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "        feature_vec[word] = round(feature_vec[word]/div,2)\n",
    "            \n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mvb = [extract_MVB_features(corpus) for corpus in X]\n",
    "X_m = [extract_M_features(corpus) for corpus in X]\n",
    "X_mn = [extract_MNorm_features(corpus) for corpus in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mvb = y.copy()\n",
    "y_m = y.copy()\n",
    "y_mn = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train_mvb, X_test_mvb, y_train_mvb, y_test_mvb = train_test_split(X_mvb, y_mvb, test_size=0.2, random_state=0)  \n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y_m, test_size=0.2, random_state=0)\n",
    "X_train_mn, X_test_mn, y_train_mn, y_test_mn = train_test_split(X_mn, y_mn, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 1619, 'ENTERTAINMENT': 1628, 'HEALTH': 1605, 'TRAVEL': 1568, 'BUSINESS': 1593, 'SPORTS': 1589, 'SCIENCE': 1597}\n",
      "{'POLITICS': 381, 'ENTERTAINMENT': 372, 'HEALTH': 394, 'TRAVEL': 432, 'BUSINESS': 407, 'SPORTS': 411, 'SCIENCE': 403}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(zip(X_train, y_train), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))\n",
    "print(count_samples_per_cat(zip(X_test, y_test), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building - Naive Bayes Classifier\n",
    "\n",
    "### Multi-Variate Bernoulli Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVB: 0\n",
      "Most Informative Features\n",
      "                  travel = 1              TRAVEL : ENTERT =    233.6 : 1.0\n",
      "                   trump = 1              POLITI : TRAVEL =    195.8 : 1.0\n",
      "               scientist = 1              SCIENC : SPORTS =    135.0 : 1.0\n",
      "                   studi = 1              SCIENC : ENTERT =    103.0 : 1.0\n",
      "                research = 1              SCIENC : ENTERT =     98.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "bayes_classifier_mvb = nltk.NaiveBayesClassifier.train(zip(X_train_mvb, y_train_mvb))\n",
    "print(\"MVB: \"+str(nltk.classify.accuracy(bayes_classifier_mvb, zip(X_test_mvb, y_test_mvb))))\n",
    "bayes_classifier_mvb.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_classifier = LogisticRegression(solver='lbfgs', multi_class = 'auto')\n",
    "log_classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 6-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(log_classifier, X, y, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "\n",
    "bnb_classifier = BernoulliNB()\n",
    "bnb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bnb_classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(bnb_classifier, X, y, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_classifier = svm.SVC(gamma='scale', max_iter = 10)\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randforest_classifier = RandomForestClassifier(n_estimators=10, random_state=0)  \n",
    "randforest_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randforest_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(log_classifier, open(\"log_classifier.model\", 'wb'))\n",
    "pickle.dump(tfidf, open(\"tfidf_kaggledataset.model\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3 as urllib\n",
    "urllib.disable_warnings()\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classes used: \",'POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyt_retrieve(nyt_rss_url, label): # retrieve articles from New York Times\n",
    "    articles = []\n",
    "    \n",
    "    # code dependent on the nytimes structure of RSS feed\n",
    "    http = urllib.PoolManager()\n",
    "    r = http.request('GET', nyt_rss_url)\n",
    "\n",
    "    data = xmltodict.parse(r.data)\n",
    "    data = data[\"rss\"]\n",
    "    data = data[\"channel\"]\n",
    "    data = data[\"item\"]\n",
    "\n",
    "    for key in data:\n",
    "        article = key\n",
    "        title, descr, extra_descr = \"\", \"\", \"\"\n",
    "        if \"title\" in article and article[\"title\"] is not None:\n",
    "            title = article[\"title\"] + \". \"\n",
    "        if \"media:description\" in article and article[\"media:description\"] is not None:\n",
    "            descr = article[\"media:description\"]\n",
    "        if \"description\" in article and article[\"description\"] is not None:\n",
    "            extra_descr = article[\"description\"]\n",
    "\n",
    "        corpus = str(title) + str(descr) + str(extra_descr)\n",
    "        articles.append(tuple((corpus, label)))\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = []\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Politics.xml', 'POLITICS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Movies.xml', 'ENTERTAINMENT')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Health.xml', 'HEALTH')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Travel.xml', 'TRAVEL')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Business.xml', 'BUSINESS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Sports.xml', 'SPORTS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Science.xml', 'SCIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nyt = []\n",
    "for corpus, label in nyt:\n",
    "    p_nyt.append(tuple((preprocess_document(corpus),label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen, y_unseen = [], []\n",
    "for corpus, label in nyt:\n",
    "    X_unseen.append(corpus)\n",
    "    y_unseen.append(label)\n",
    "\n",
    "X_unseen = tfidf.transform(X_unseen).toarray()\n",
    "\n",
    "y_pred = bnb_classifier.predict(X_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_unseen,y_pred))  \n",
    "print(classification_report(y_unseen,y_pred))  \n",
    "print(accuracy_score(y_unseen, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
