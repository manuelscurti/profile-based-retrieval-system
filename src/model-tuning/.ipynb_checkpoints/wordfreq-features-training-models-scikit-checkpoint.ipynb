{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../../material/data/news_dataset.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#allowed_categories = ['POLITICS', 'TRAVEL', 'SPORTS', 'RELIGION', 'SCIENCE', 'TECH', 'ARTS']\n",
    "allowed_categories = {'POLITICS': 0, 'ENTERTAINMENT': 0, 'HEALTHY LIVING': 0, 'TRAVEL': 0, 'BUSINESS': 0, 'SPORTS':0, 'SCIENCE': 0}\n",
    "\n",
    "#max_per_cat = 1000\n",
    "\n",
    "filtered_data = []\n",
    "filter_date = datetime.strptime('2017-08-01', \"%Y-%m-%d\")\n",
    "\n",
    "for dct in data:\n",
    "    if dct['category'] in allowed_categories:\n",
    "        datetime_object = datetime.strptime(dct['date'], '%Y-%m-%d')\n",
    "        if dct['category'] in ['POLITICS', 'ENTERTAINMENT']:\n",
    "            if datetime_object >= filter_date:\n",
    "                filtered_data.append(dct)\n",
    "                allowed_categories[dct['category']]+=1\n",
    "        else:\n",
    "            filtered_data.append(dct)\n",
    "            allowed_categories[dct['category']]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POLITICS': 7049,\n",
       " 'ENTERTAINMENT': 3058,\n",
       " 'HEALTHY LIVING': 6694,\n",
       " 'TRAVEL': 9887,\n",
       " 'BUSINESS': 5937,\n",
       " 'SPORTS': 4884,\n",
       " 'SCIENCE': 2178}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "politics = []\n",
    "entertainment = []\n",
    "health = []\n",
    "travel = []\n",
    "business = []\n",
    "sports = []\n",
    "science = []\n",
    "\n",
    "for dct in filtered_data:\n",
    "    if dct['category'] == \"POLITICS\":\n",
    "        politics.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"POLITICS\")))\n",
    "    if dct['category'] == \"ENTERTAINMENT\":\n",
    "        entertainment.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"ENTERTAINMENT\")))\n",
    "    if dct['category'] == \"HEALTHY LIVING\":\n",
    "        health.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"HEALTH\")))\n",
    "    if dct['category'] == \"TRAVEL\":\n",
    "        travel.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"TRAVEL\")))\n",
    "    if dct['category'] == \"BUSINESS\":\n",
    "        business.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"BUSINESS\")))\n",
    "    if dct['category'] == \"SPORTS\":\n",
    "        sports.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SPORTS\")))\n",
    "    if dct['category'] == \"SCIENCE\":\n",
    "        science.append(tuple((str(dct['headline']) + '. ' + str(dct['short_description']), \"SCIENCE\")))\n",
    "        \n",
    "max_samples = 2000\n",
    "politics = random.sample(politics, max_samples)\n",
    "entertainment = random.sample(entertainment, max_samples)\n",
    "health = random.sample(health, max_samples)\n",
    "travel = random.sample(travel, max_samples)\n",
    "business = random.sample(business, max_samples)\n",
    "sports = random.sample(sports, max_samples)\n",
    "science = random.sample(science, max_samples)\n",
    "\n",
    "articles = politics + entertainment + health + travel + business + sports + science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_samples_per_cat(samples, cats):\n",
    "    counts = {}\n",
    "    for name in cats:\n",
    "        counts[name] = 0\n",
    "    \n",
    "    for corpus, label in samples:\n",
    "        counts[label]+=1\n",
    "        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 2000, 'ENTERTAINMENT': 2000, 'HEALTH': 2000, 'TRAVEL': 2000, 'BUSINESS': 2000, 'SPORTS': 2000, 'SCIENCE': 2000}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(articles, ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
    "    final = [stemmer.stem(word) for word in clean]\n",
    "    return \" \".join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_articles = []\n",
    "for corpus, label in articles:\n",
    "    p_corpus = preprocess_document(corpus)\n",
    "    p_articles.append(tuple((p_corpus, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 8614)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "X = [corpus for corpus, label in articles]\n",
    "y = [label for corpus, label in articles]\n",
    "\n",
    "X = tfidf.fit_transform(X).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POLITICS': 1619, 'ENTERTAINMENT': 1628, 'HEALTH': 1606, 'TRAVEL': 1580, 'BUSINESS': 1591, 'SPORTS': 1578, 'SCIENCE': 1598}\n",
      "{'POLITICS': 381, 'ENTERTAINMENT': 372, 'HEALTH': 394, 'TRAVEL': 420, 'BUSINESS': 409, 'SPORTS': 422, 'SCIENCE': 402}\n"
     ]
    }
   ],
   "source": [
    "print(count_samples_per_cat(zip(X_train, y_train), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))\n",
    "print(count_samples_per_cat(zip(X_test, y_test), ['POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=400, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_classifier = LogisticRegression(solver='lbfgs', multi_class = 'auto', verbose=2, max_iter = 400)\n",
    "log_classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[308  14  38  19  10   8  12]\n",
      " [  9 310  11  21   8   9   4]\n",
      " [ 27   6 307   8  24   8  14]\n",
      " [ 24  11  16 312   5   8   5]\n",
      " [ 15  11  45   5 300   5  21]\n",
      " [  6  15  14  10   4 359  14]\n",
      " [ 11  12  18   6  15   7 351]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.77      0.75      0.76       409\n",
      "ENTERTAINMENT       0.82      0.83      0.83       372\n",
      "       HEALTH       0.68      0.78      0.73       394\n",
      "     POLITICS       0.82      0.82      0.82       381\n",
      "      SCIENCE       0.82      0.75      0.78       402\n",
      "       SPORTS       0.89      0.85      0.87       422\n",
      "       TRAVEL       0.83      0.84      0.83       420\n",
      "\n",
      "    micro avg       0.80      0.80      0.80      2800\n",
      "    macro avg       0.80      0.80      0.80      2800\n",
      " weighted avg       0.81      0.80      0.80      2800\n",
      "\n",
      "0.8025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 6-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   30.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   29.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   32.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   32.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   26.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(log_classifier, X, y, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79512404 0.78100941 0.7979408  0.7992278  0.8005148  0.80652081]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3667946077624151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import time\n",
    "\n",
    "bnb_classifier = BernoulliNB(fit_prior=True)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "bnb_classifier.fit(X_train, y_train)\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bnb_classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259  12  75  22  11  16  14]\n",
      " [  4 309  19  17   6  14   3]\n",
      " [ 24  12 315   9  15   9  10]\n",
      " [ 26  17  15 309   4   8   2]\n",
      " [ 11  14  61   6 287   7  16]\n",
      " [  4  21  15   8   3 360  11]\n",
      " [ 14  10  24   4  15   5 348]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.76      0.63      0.69       409\n",
      "ENTERTAINMENT       0.78      0.83      0.81       372\n",
      "       HEALTH       0.60      0.80      0.69       394\n",
      "     POLITICS       0.82      0.81      0.82       381\n",
      "      SCIENCE       0.84      0.71      0.77       402\n",
      "       SPORTS       0.86      0.85      0.86       422\n",
      "       TRAVEL       0.86      0.83      0.84       420\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      2800\n",
      "    macro avg       0.79      0.78      0.78      2800\n",
      " weighted avg       0.79      0.78      0.78      2800\n",
      "\n",
      "0.7810714285714285\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(bnb_classifier, X, y, cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78999145, 0.77459367, 0.78378378, 0.7987988 , 0.7979408 ,\n",
       "       0.78807379])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=400, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "svm_classifier = svm.SVC(gamma='scale', max_iter = 400)\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   2  43  28  19  32 165]\n",
      " [  0 199  14  23  13  47  76]\n",
      " [  9   2 186  11  53  23 110]\n",
      " [  4   7   2 260  16  41  51]\n",
      " [  2   4  15   2 258  17 104]\n",
      " [  1   5   4   2   8 328  74]\n",
      " [  0   1   4   3   5   5 402]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.88      0.29      0.44       409\n",
      "ENTERTAINMENT       0.90      0.53      0.67       372\n",
      "       HEALTH       0.69      0.47      0.56       394\n",
      "     POLITICS       0.79      0.68      0.73       381\n",
      "      SCIENCE       0.69      0.64      0.67       402\n",
      "       SPORTS       0.67      0.78      0.72       422\n",
      "       TRAVEL       0.41      0.96      0.57       420\n",
      "\n",
      "    micro avg       0.63      0.63      0.63      2800\n",
      "    macro avg       0.72      0.62      0.62      2800\n",
      " weighted avg       0.72      0.63      0.62      2800\n",
      "\n",
      "0.6260714285714286\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randforest_classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "randforest_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = randforest_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255  12  73  17  14  18  20]\n",
      " [ 11 268  32  27   9  19   6]\n",
      " [ 21  12 285   9  41  12  14]\n",
      " [ 20  16  29 293  11   4   8]\n",
      " [ 14  11  66   7 272   9  23]\n",
      " [ 12  22  36  13   7 313  19]\n",
      " [ 14  16  46   7  13  11 313]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.73      0.62      0.67       409\n",
      "ENTERTAINMENT       0.75      0.72      0.74       372\n",
      "       HEALTH       0.50      0.72      0.59       394\n",
      "     POLITICS       0.79      0.77      0.78       381\n",
      "      SCIENCE       0.74      0.68      0.71       402\n",
      "       SPORTS       0.81      0.74      0.77       422\n",
      "       TRAVEL       0.78      0.75      0.76       420\n",
      "\n",
      "    micro avg       0.71      0.71      0.71      2800\n",
      "    macro avg       0.73      0.71      0.72      2800\n",
      " weighted avg       0.73      0.71      0.72      2800\n",
      "\n",
      "0.7139285714285715\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(log_classifier, open(\"log_classifier.model\", 'wb'))\n",
    "pickle.dump(tfidf, open(\"tfidf_kaggledataset.model\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3 as urllib\n",
    "urllib.disable_warnings()\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used:  POLITICS ENTERTAINMENT HEALTH TRAVEL BUSINESS SPORTS SCIENCE\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes used: \",'POLITICS', 'ENTERTAINMENT', 'HEALTH', 'TRAVEL', 'BUSINESS', 'SPORTS', 'SCIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyt_retrieve(nyt_rss_url, label): # retrieve articles from New York Times\n",
    "    articles = []\n",
    "    \n",
    "    # code dependent on the nytimes structure of RSS feed\n",
    "    http = urllib.PoolManager()\n",
    "    r = http.request('GET', nyt_rss_url)\n",
    "\n",
    "    data = xmltodict.parse(r.data)\n",
    "    data = data[\"rss\"]\n",
    "    data = data[\"channel\"]\n",
    "    data = data[\"item\"]\n",
    "\n",
    "    for key in data:\n",
    "        article = key\n",
    "        title, descr, extra_descr = \"\", \"\", \"\"\n",
    "        if \"title\" in article and article[\"title\"] is not None:\n",
    "            title = article[\"title\"] + \". \"\n",
    "        if \"media:description\" in article and article[\"media:description\"] is not None:\n",
    "            descr = article[\"media:description\"]\n",
    "        if \"description\" in article and article[\"description\"] is not None:\n",
    "            extra_descr = article[\"description\"]\n",
    "\n",
    "        corpus = str(title) + str(descr) + str(extra_descr)\n",
    "        articles.append(tuple((corpus, label)))\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = []\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Politics.xml', 'POLITICS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Movies.xml', 'ENTERTAINMENT')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Health.xml', 'HEALTH')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Travel.xml', 'TRAVEL')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Business.xml', 'BUSINESS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Sports.xml', 'SPORTS')\n",
    "nyt += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Science.xml', 'SCIENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nyt = []\n",
    "for corpus, label in nyt:\n",
    "    p_nyt.append(tuple((preprocess_document(corpus),label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen, y_unseen = [], []\n",
    "for corpus, label in p_nyt:\n",
    "    X_unseen.append(corpus)\n",
    "    y_unseen.append(label)\n",
    "\n",
    "X_unseen = tfidf.transform(X_unseen).toarray()\n",
    "\n",
    "y_pred = bnb_classifier.predict(X_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  2  1  5  2  1  3]\n",
      " [ 1 27  2  0  2  0  1]\n",
      " [ 4  1 13  7  5  2  1]\n",
      " [ 1  0  0 18  0  0  1]\n",
      " [ 4  0  5  7  8  0  2]\n",
      " [ 1  0  0  0  0 18  1]\n",
      " [ 2  0  0  1  2  0 18]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     BUSINESS       0.72      0.71      0.72        48\n",
      "ENTERTAINMENT       0.90      0.82      0.86        33\n",
      "       HEALTH       0.62      0.39      0.48        33\n",
      "     POLITICS       0.47      0.90      0.62        20\n",
      "      SCIENCE       0.42      0.31      0.36        26\n",
      "       SPORTS       0.86      0.90      0.88        20\n",
      "       TRAVEL       0.67      0.78      0.72        23\n",
      "\n",
      "    micro avg       0.67      0.67      0.67       203\n",
      "    macro avg       0.67      0.69      0.66       203\n",
      " weighted avg       0.68      0.67      0.66       203\n",
      "\n",
      "0.6699507389162561\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_unseen,y_pred))  \n",
    "print(classification_report(y_unseen,y_pred))  \n",
    "print(accuracy_score(y_unseen, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
