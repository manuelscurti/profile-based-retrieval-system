{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Based Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manue\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim import corpora, models, similarities\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "import urllib3 as urllib\n",
    "urllib.disable_warnings()\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(doc):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = wordpunct_tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
    "    final = [stemmer.stem(word) for word in clean]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_category_samples(articles, category):\n",
    "    count = 0\n",
    "    for corpus, label in articles:\n",
    "        if category == label:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_samples(samples, division): # consistent split\n",
    "    \n",
    "    samples_p = [(corpus, label) for (corpus, label) in samples if label == 'Politics']\n",
    "    samples_b = [(corpus, label) for (corpus, label) in samples if label == 'Business']\n",
    "    samples_t = [(corpus, label) for (corpus, label) in samples if label == 'Tech']\n",
    "    samples_s = [(corpus, label) for (corpus, label) in samples if label == 'Science']\n",
    "    samples_h = [(corpus, label) for (corpus, label) in samples if label == 'Health']\n",
    "    samples_sp = [(corpus, label) for (corpus, label) in samples if label == 'Sports']\n",
    "    samples_a = [(corpus, label) for (corpus, label) in samples if label == 'Arts']\n",
    "    \n",
    "    train_p = samples_p[:int(division*len(samples_p))]\n",
    "    test_p = samples_p[int(division*len(samples_p)):]\n",
    "    \n",
    "    train_b = samples_b[:int(division*len(samples_b))]\n",
    "    test_b = samples_b[int(division*len(samples_b)):]\n",
    "    \n",
    "    train_t = samples_t[:int(division*len(samples_t))]\n",
    "    test_t = samples_t[int(division*len(samples_t)):]\n",
    "    \n",
    "    train_s = samples_s[:int(division*len(samples_s))]\n",
    "    test_s = samples_s[int(division*len(samples_s)):]\n",
    "    \n",
    "    train_h = samples_h[:int(division*len(samples_h))]\n",
    "    test_h = samples_h[int(division*len(samples_h)):]\n",
    "    \n",
    "    train_sp = samples_sp[:int(division*len(samples_sp))]\n",
    "    test_sp = samples_sp[int(division*len(samples_sp)):]\n",
    "\n",
    "    train_a = samples_a[:int(division*len(samples_a))]\n",
    "    test_a = samples_a[int(division*len(samples_a)):]\n",
    "    \n",
    "    trainset = train_p + train_b + train_t + train_s + train_h + train_sp + train_a\n",
    "    testset = test_p + test_b + test_t + test_s + test_h + test_sp + test_a\n",
    "    \n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [] # container for all the retrieved articles in the form corpus-category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nyt_retrieve(nyt_rss_url, label): # retrieve articles from New York Times\n",
    "    articles = []\n",
    "    \n",
    "    # code dependent on the nytimes structure of RSS feed\n",
    "    http = urllib.PoolManager()\n",
    "    r = http.request('GET', nyt_rss_url)\n",
    "\n",
    "    data = xmltodict.parse(r.data)\n",
    "    data = data[\"rss\"]\n",
    "    data = data[\"channel\"]\n",
    "    data = data[\"item\"]\n",
    "\n",
    "    for key in data:\n",
    "        article = key\n",
    "        title, descr, extra_descr = \"\", \"\", \"\"\n",
    "        if \"title\" in article and article[\"title\"] is not None:\n",
    "            title = article[\"title\"] + \". \"\n",
    "        if \"media:description\" in article and article[\"media:description\"] is not None:\n",
    "            descr = article[\"media:description\"]\n",
    "        if \"description\" in article and article[\"description\"] is not None:\n",
    "            extra_descr = article[\"description\"]\n",
    "\n",
    "        corpus = str(title) + str(descr) + str(extra_descr)\n",
    "        articles.append(tuple((corpus, label)))\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbc_retrieve(rss_url, label): # retrieve from BBC\n",
    "    articles = []\n",
    "    \n",
    "    http = urllib.PoolManager()\n",
    "    r = http.request('GET', rss_url)\n",
    "    \n",
    "    data = xmltodict.parse(r.data)\n",
    "    data = data[\"rss\"]\n",
    "    data = data[\"channel\"]\n",
    "    data = data[\"item\"]\n",
    "    \n",
    "    for key in data:\n",
    "        article = key\n",
    "        title,descr = '', ''\n",
    "        if 'title' in article and article['title'] is not None:\n",
    "            title = article['title']+'. '\n",
    "        if 'description' in article and article['description'] is not None:\n",
    "            descr = article['description']\n",
    "\n",
    "        corpus = str(title) + str(descr)\n",
    "        articles.append(tuple((corpus, label)))\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theguardian_retrieve(rss_url, label): # retrieve from TheGuardian\n",
    "    articles = []\n",
    "    \n",
    "    http = urllib.PoolManager()\n",
    "    r = http.request('GET', rss_url)\n",
    "    \n",
    "    data = xmltodict.parse(r.data)\n",
    "    data = data[\"rss\"]\n",
    "    data = data[\"channel\"]\n",
    "    data = data[\"item\"]\n",
    "    \n",
    "    for key in data:\n",
    "        article = key\n",
    "        title,descr = '', ''\n",
    "        if 'title' in article and article['title'] is not None:\n",
    "            title = article['title']\n",
    "            \n",
    "        corpus = str(title)\n",
    "        articles.append(tuple((corpus, label)))\n",
    "        \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles += theguardian_retrieve('https://www.theguardian.com/politics/rss', 'Politics')\n",
    "articles += theguardian_retrieve('https://www.theguardian.com/uk/business/rss', 'Business')\n",
    "articles += theguardian_retrieve('https://www.theguardian.com/uk/technology/rss', 'Tech')\n",
    "articles += theguardian_retrieve('https://www.theguardian.com/science/rss', 'Science')\n",
    "articles += theguardian_retrieve('https://www.theguardian.com/lifeandstyle/health-and-wellbeing/rss', 'Health')\n",
    "articles += theguardian_retrieve('https://www.theguardian.com/uk/sport/rss', 'Sports')\n",
    "articles += theguardian_retrieve('https://www.theguardian.com/uk/culture/rss', 'Arts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/news/politics/rss.xml', 'Politics')\n",
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/news/business/rss.xml', 'Business')\n",
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/news/technology/rss.xml', 'Tech')\n",
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/news/science_and_environment/rss.xml', 'Science')\n",
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/news/health/rss.xml', 'Health')\n",
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/sport/rss.xml', 'Sports')\n",
    "articles += bbc_retrieve('http://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml', 'Arts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Politics.xml', 'Politics')\n",
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Business.xml', 'Business')\n",
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Technology.xml', 'Tech')\n",
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Science.xml', 'Science')\n",
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Health.xml', 'Health')\n",
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Sports.xml', 'Sports')\n",
    "articles += nyt_retrieve('http://rss.nytimes.com/services/xml/rss/nyt/Arts.xml', 'Arts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866\n"
     ]
    }
   ],
   "source": [
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              corpus     label\n",
      "0  Labour says Theresa May unwilling to offer key...  Politics\n",
      "1  Brexit: Theresa May's approval ratings with To...  Politics\n",
      "2  Ann Widdecombe stands for Farage's Brexit part...  Politics\n",
      "3  Greta Thunberg condemns UK's climate stance in...  Politics\n",
      "4  Trump baby blimp back and could be even bigger...  Politics\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(articles, columns=['corpus', 'label'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv('articles20190424.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.isna().sum()\n",
    "(df['label'].values == '').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Corpus of the articles are cleaned applying stop words removal, PorterStemmer, tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['brexit', 'theresa', 'may', 'approv', 'rate', 'tori', 'member', 'hit', 'record', 'low', 'survey', 'suggest', 'live', 'news'], 'Politics'), (['ann', 'widdecomb', 'stand', 'farag', 'brexit', 'parti', 'european', 'elect'], 'Politics')]\n",
      "866\n"
     ]
    }
   ],
   "source": [
    "p_articles = []\n",
    "for corpus, title in articles:\n",
    "    p_corpus = preprocess_document(corpus)\n",
    "    p_articles.append(tuple((p_corpus, title)))\n",
    "\n",
    "print(p_articles[1:3])\n",
    "print(len(p_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "### Create dictionary for Multi-Variate Bernoulli, Multinomial and Normalized Multinomial feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15306\n",
      "<FreqDist with 4344 samples and 15306 outcomes>\n",
      "1000\n",
      "['say', 'brexit', 'year', 'time']\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "dict_from_articles = [] # list of all tokens contained in the whole set of articles\n",
    "for tokens, label in p_articles:\n",
    "    dict_from_articles = dict_from_articles + tokens\n",
    "\n",
    "print(len(dict_from_articles))\n",
    "fdist = FreqDist(dict_from_articles) # compute frequency distribution\n",
    "\n",
    "print(fdist)\n",
    "topK = fdist.most_common(1000)\n",
    "\n",
    "dictionary = []\n",
    "for word, count in topK:\n",
    "    dictionary.append(word)\n",
    "    \n",
    "print(len(dictionary))\n",
    "print(dictionary[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary for Tf-Idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MVB_features(tokens):\n",
    "    feature_vec = {}\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if word in tokens:\n",
    "            feature_vec[word] = 1\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "            \n",
    "    return feature_vec\n",
    "\n",
    "def extract_M_features(tokens):\n",
    "    feature_vec = {}\n",
    "    freqs = FreqDist(tokens)\n",
    "        \n",
    "    for word in dictionary:\n",
    "        if word in freqs: # if word appears in the phrase\n",
    "            feature_vec[word] = freqs[word]\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "            \n",
    "    return feature_vec\n",
    "\n",
    "def extract_MNorm_features(tokens):\n",
    "    feature_vec = {}\n",
    "    freqs = FreqDist(tokens)\n",
    "    div = len(tokens)\n",
    "    \n",
    "    for word in dictionary:\n",
    "        if word in freqs: # if word appears in the phrase\n",
    "            feature_vec[word] = freqs[word]\n",
    "        else:\n",
    "            feature_vec[word] = 0\n",
    "        feature_vec[word] = round(feature_vec[word]/div,2)\n",
    "            \n",
    "    return feature_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data we create train set (80%) and test set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "163\n",
      "151\n",
      "106\n",
      "83\n",
      "92\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(p_articles)\n",
    "\n",
    "print(count_category_samples(p_articles, 'Politics'))\n",
    "print(count_category_samples(p_articles, 'Business'))\n",
    "print(count_category_samples(p_articles, 'Tech'))\n",
    "print(count_category_samples(p_articles, 'Science'))\n",
    "print(count_category_samples(p_articles, 'Health'))\n",
    "print(count_category_samples(p_articles, 'Sports'))\n",
    "print(count_category_samples(p_articles, 'Arts'))\n",
    "\n",
    "featuresets_mvb = [(extract_MVB_features(corpus), label) for (corpus, label) in p_articles]\n",
    "featuresets_m = [(extract_M_features(corpus), label) for (corpus, label) in p_articles]\n",
    "featuresets_mn = [(extract_MNorm_features(corpus), label) for (corpus, label) in p_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_mvb, testset_mvb = split_samples(featuresets_mvb, 0.8)\n",
    "trainset_m, testset_m = split_samples(featuresets_m, 0.8)\n",
    "trainset_mn, testset_mn = split_samples(featuresets_mn, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "### Multi-Variate Bernoulli Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVB: 0.536723163841808\n",
      "Most Informative Features\n",
      "                  health = 1              Health : Busine =     15.0 : 1.0\n",
      "                  brexit = 1              Politi : Busine =     14.8 : 1.0\n",
      "                     may = 1              Politi : Busine =     14.7 : 1.0\n",
      "                  review = 1                Arts : Busine =     14.2 : 1.0\n",
      "                     win = 1              Sports : Politi =     13.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "bayes_classifier_mvb = nltk.NaiveBayesClassifier.train(trainset_mvb)\n",
    "print(\"MVB: \"+str(nltk.classify.accuracy(bayes_classifier_mvb, testset_mvb)))\n",
    "bayes_classifier_mvb.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 0.4858757062146893\n",
      "Most Informative Features\n",
      "                  review = 1                Arts : Busine =     13.3 : 1.0\n",
      "                     may = 1              Politi : Busine =     13.1 : 1.0\n",
      "                     win = 1              Sports : Politi =     12.4 : 1.0\n",
      "                  health = 1              Health : Tech   =     11.4 : 1.0\n",
      "                    citi = 1              Sports : Busine =     11.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "bayes_classifier_m = nltk.NaiveBayesClassifier.train(trainset_m)\n",
    "print(\"M: \"+str(nltk.classify.accuracy(bayes_classifier_m, testset_m)))\n",
    "bayes_classifier_m.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNorm: 0.3107344632768362\n",
      "Most Informative Features\n",
      "                     may = 0.06           Health : Busine =      5.7 : 1.0\n",
      "                   first = 0.03           Sports : Busine =      5.2 : 1.0\n",
      "                   three = 0.03           Sports : Tech   =      4.8 : 1.0\n",
      "                 product = 0.05           Health : Busine =      4.5 : 1.0\n",
      "                   could = 0.06           Health : Busine =      4.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "bayes_classifier_mn = nltk.NaiveBayesClassifier.train(trainset_mn)\n",
    "print(\"MNorm: \"+str(nltk.classify.accuracy(bayes_classifier_mn, testset_mn)))\n",
    "bayes_classifier_mn.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Entropy Classification\n",
    "\n",
    "### Multi-Variate Bernoulli Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent_classifier_mvb = nltk.classify.MaxentClassifier.train(trainset_mvb, 'IIS', trace=0, max_iter=5)\n",
    "print(\"MVB: \"+str(nltk.classify.accuracy(maxent_classifier_mvb, testset_mvb)))\n",
    "maxent_classifier_mvb.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent_classifier_m = nltk.classify.MaxentClassifier.train(trainset_m, 'IIS', trace=0, max_iter=5)\n",
    "print(\"M: \"+str(nltk.classify.accuracy(maxent_classifier_m, testset_m)))\n",
    "maxent_classifier_m.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxent_classifier_mn = nltk.classify.MaxentClassifier.train(trainset_mn, 'IIS', trace=0, max_iter=5)\n",
    "print(\"MNorm: \"+str(nltk.classify.accuracy(maxent_classifier_mn, testset_mn)))\n",
    "maxent_classifier_mn.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "### Multi-Variate Bernoulli Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randforest_classifier_mvb = nltk.classify.DecisionTreeClassifier.train(trainset_mvb, entropy_cutoff=0, support_cutoff=0)\n",
    "print(\"MVB: \"+str(nltk.classify.accuracy(randforest_classifier_mvb, testset_mvb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randforest_classifier_m = nltk.classify.DecisionTreeClassifier.train(trainset_m, entropy_cutoff=0, support_cutoff=0)\n",
    "print(\"M: \"+str(nltk.classify.accuracy(randforest_classifier_m, testset_m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Multinomial Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randforest_classifier_mn = nltk.classify.DecisionTreeClassifier.train(trainset_mn, entropy_cutoff=0, support_cutoff=0)\n",
    "print(\"MNorm: \"+str(nltk.classify.accuracy(randforest_classifier_mn, testset_mn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "Since it is the best performing model among the ones I tried, I choose to use the Naive Bayes Classifier trained with Multi-Variate Bernoulli Feature Set to be used into the profile-based retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('nbayes-mvb.pickle', 'wb')\n",
    "pickle.dump(bayes_classifier_mvb, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### how to load a saved model? \n",
    "# import pickle\n",
    "# f = open('my_classifier.pickle', 'rb')\n",
    "# classifier = pickle.load(f)\n",
    "# f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
